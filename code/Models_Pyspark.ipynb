{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6TOo3JE7PPm",
        "outputId": "676d5986-3e94-45c9-8c08-2c234d6a5e13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=a1d96b3121c74946baaafbad4e5879742a05b973a1dc3a238362639b942017dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pmSzcYGo6s10"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.tuning import TrainValidationSplit\n",
        "from pyspark.ml.linalg import Vectors, VectorUDT\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('BigDataProject').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cmi4B0nB6s12",
        "outputId": "761c0422-2de7-4490-a482-829b2d31efa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score before oversampling:  0.9125689895089042\n",
            "Confusion matrix before oversampling: \n",
            " [[58367     0]\n",
            " [ 5592     0]]\n",
            "Classification report before oversampling: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95     58367\n",
            "           1       0.00      0.00      0.00      5592\n",
            "\n",
            "    accuracy                           0.91     63959\n",
            "   macro avg       0.46      0.50      0.48     63959\n",
            "weighted avg       0.83      0.91      0.87     63959\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(468110, 17)\n",
            "(468110,)\n",
            "Accuracy score after oversampling:  0.7250113353867321\n",
            "Confusion matrix after oversampling: \n",
            " [[42175 16192]\n",
            " [ 1396  4196]]\n",
            "Classification report after oversampling: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.72      0.83     58367\n",
            "           1       0.21      0.75      0.32      5592\n",
            "\n",
            "    accuracy                           0.73     63959\n",
            "   macro avg       0.59      0.74      0.58     63959\n",
            "weighted avg       0.90      0.73      0.78     63959\n",
            "\n",
            "+-----+-------+---------------+------+--------------+------------+-----------+---+-----------+----+--------+----------------+---------+---------+------+-------------+----------+------------+----------------------------------------------------------------------------+\n",
            "|BMI  |Smoking|AlcoholDrinking|Stroke|PhysicalHealth|MentalHealth|DiffWalking|Sex|AgeCategory|Race|Diabetic|PhysicalActivity|GenHealth|SleepTime|Asthma|KidneyDisease|SkinCancer|HeartDisease|Fvec                                                                        |\n",
            "+-----+-------+---------------+------+--------------+------------+-----------+---+-----------+----+--------+----------------+---------+---------+------+-------------+----------+------------+----------------------------------------------------------------------------+\n",
            "|23.33|1      |0              |0     |0.0           |0.0         |0          |1  |11         |0   |0       |1               |3        |7.0      |0     |0            |0         |0           |(17,[0,1,7,8,11,12,13],[23.33,1.0,1.0,11.0,1.0,3.0,7.0])                    |\n",
            "|27.46|1      |0              |1     |30.0          |0.0         |0          |1  |7          |0   |0       |1               |2        |6.0      |0     |0            |0         |1           |(17,[0,1,3,4,7,8,11,12,13],[27.46,1.0,1.0,30.0,1.0,7.0,1.0,2.0,6.0])        |\n",
            "|32.69|0      |0              |0     |2.0           |2.0         |0          |1  |6          |5   |0       |0               |3        |8.0      |0     |0            |0         |0           |(17,[0,4,5,7,8,9,12,13],[32.69,2.0,2.0,1.0,6.0,5.0,3.0,8.0])                |\n",
            "|31.32|0      |0              |0     |0.0           |0.0         |0          |0  |1          |0   |0       |1               |4        |8.0      |0     |0            |0         |0           |(17,[0,8,11,12,13],[31.32,1.0,1.0,4.0,8.0])                                 |\n",
            "|24.63|1      |0              |0     |2.0           |10.0        |0          |1  |12         |0   |2       |1               |2        |7.0      |0     |0            |0         |1           |(17,[0,1,4,5,7,8,10,11,12,13],[24.63,1.0,2.0,10.0,1.0,12.0,2.0,1.0,2.0,7.0])|\n",
            "+-----+-------+---------------+------+--------------+------------+-----------+---+-----------+----+--------+----------------+---------+---------+------+-------------+----------+------------+----------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----+-------+---------------+------+--------------+------------+-----------+---+-----------+----+--------+----------------+---------+---------+------+-------------+----------+------------+----------------------------------------------------------------------------+-------------------------------------------------------------------------+\n",
            "|BMI  |Smoking|AlcoholDrinking|Stroke|PhysicalHealth|MentalHealth|DiffWalking|Sex|AgeCategory|Race|Diabetic|PhysicalActivity|GenHealth|SleepTime|Asthma|KidneyDisease|SkinCancer|HeartDisease|Fvec                                                                        |DenseFvec                                                                |\n",
            "+-----+-------+---------------+------+--------------+------------+-----------+---+-----------+----+--------+----------------+---------+---------+------+-------------+----------+------------+----------------------------------------------------------------------------+-------------------------------------------------------------------------+\n",
            "|23.33|1      |0              |0     |0.0           |0.0         |0          |1  |11         |0   |0       |1               |3        |7.0      |0     |0            |0         |0           |(17,[0,1,7,8,11,12,13],[23.33,1.0,1.0,11.0,1.0,3.0,7.0])                    |[23.33,1.0,0.0,0.0,0.0,0.0,0.0,1.0,11.0,0.0,0.0,1.0,3.0,7.0,0.0,0.0,0.0] |\n",
            "|27.46|1      |0              |1     |30.0          |0.0         |0          |1  |7          |0   |0       |1               |2        |6.0      |0     |0            |0         |1           |(17,[0,1,3,4,7,8,11,12,13],[27.46,1.0,1.0,30.0,1.0,7.0,1.0,2.0,6.0])        |[27.46,1.0,0.0,1.0,30.0,0.0,0.0,1.0,7.0,0.0,0.0,1.0,2.0,6.0,0.0,0.0,0.0] |\n",
            "|32.69|0      |0              |0     |2.0           |2.0         |0          |1  |6          |5   |0       |0               |3        |8.0      |0     |0            |0         |0           |(17,[0,4,5,7,8,9,12,13],[32.69,2.0,2.0,1.0,6.0,5.0,3.0,8.0])                |[32.69,0.0,0.0,0.0,2.0,2.0,0.0,1.0,6.0,5.0,0.0,0.0,3.0,8.0,0.0,0.0,0.0]  |\n",
            "|31.32|0      |0              |0     |0.0           |0.0         |0          |0  |1          |0   |0       |1               |4        |8.0      |0     |0            |0         |0           |(17,[0,8,11,12,13],[31.32,1.0,1.0,4.0,8.0])                                 |[31.32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,4.0,8.0,0.0,0.0,0.0]  |\n",
            "|24.63|1      |0              |0     |2.0           |10.0        |0          |1  |12         |0   |2       |1               |2        |7.0      |0     |0            |0         |1           |(17,[0,1,4,5,7,8,10,11,12,13],[24.63,1.0,2.0,10.0,1.0,12.0,2.0,1.0,2.0,7.0])|[24.63,1.0,0.0,0.0,2.0,10.0,0.0,1.0,12.0,0.0,2.0,1.0,2.0,7.0,0.0,0.0,0.0]|\n",
            "+-----+-------+---------------+------+--------------+------------+-----------+---+-----------+----+--------+----------------+---------+---------+------+-------------+----------+------------+----------------------------------------------------------------------------+-------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+------------+\n",
            "|HeartDisease|\n",
            "+------------+\n",
            "|           0|\n",
            "|           0|\n",
            "|           0|\n",
            "|           0|\n",
            "|           0|\n",
            "+------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+------------+--------------------+\n",
            "|HeartDisease|           DenseFvec|\n",
            "+------------+--------------------+\n",
            "|           0|[12.02,0.0,0.0,0....|\n",
            "|           0|[12.02,1.0,0.0,0....|\n",
            "|           0|[12.13,0.0,0.0,0....|\n",
            "|           0|[12.16,0.0,0.0,0....|\n",
            "|           0|[12.26,0.0,0.0,0....|\n",
            "+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# read data\n",
        "df = pd.read_csv('./data_cleaned.csv')\n",
        "df.head()\n",
        "\n",
        "############# checking the accuracy of the model before oversampling ###########\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('HeartDisease', axis=1), df['HeartDisease'], test_size=0.2, random_state=42)\n",
        "# create a classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
        "# fit the classifier to the training data\n",
        "clf.fit(X_train, y_train)\n",
        "# predict the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "# show the accuracy score\n",
        "print('Accuracy score before oversampling: ', accuracy_score(y_test, y_pred))\n",
        "# show the confusion matrix\n",
        "print('Confusion matrix before oversampling: \\n', confusion_matrix(y_test, y_pred))\n",
        "# show the classification report\n",
        "print('Classification report before oversampling: \\n', classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "############# checking the accuracy of the model after oversampling ############\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
        "# show the shape of the resampled data\n",
        "print(X_resampled.shape)\n",
        "print(y_resampled.shape)\n",
        "# use the resampled data to train the classifier\n",
        "clf.fit(X_resampled, y_resampled)\n",
        "# predict the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "# show the accuracy score\n",
        "print('Accuracy score after oversampling: ', accuracy_score(y_test, y_pred))\n",
        "# show the confusion matrix\n",
        "print('Confusion matrix after oversampling: \\n', confusion_matrix(y_test, y_pred))\n",
        "# show the classification report\n",
        "print('Classification report after oversampling: \\n', classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "############# combining the features in one column ############\n",
        "train_df = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "test_df = pd.concat([X_test, y_test], axis=1)\n",
        "df_resampled = pd.concat([train_df, test_df], ignore_index=True)\n",
        "df_sk = spark.createDataFrame(df_resampled)\n",
        "# df_sk = spark.createDataFrame(df)\n",
        "# Define a function to convert sparse vectors to dense vectors\n",
        "def sparse_to_dense(vector):\n",
        "    return Vectors.dense(vector)\n",
        "\n",
        "# Register the function as a UDF\n",
        "sparse_to_dense_udf = udf(sparse_to_dense, VectorUDT())\n",
        "\n",
        "# Combine all feature columns into a single vector column\n",
        "assembler = VectorAssembler(inputCols=df_sk.drop('HeartDisease').columns, outputCol='Fvec')\n",
        "df_sk = assembler.transform(df_sk)\n",
        "df_sk.show(5, truncate=False)\n",
        "df_sk = df_sk.withColumn('DenseFvec', sparse_to_dense_udf(df_sk['Fvec']))\n",
        "df_sk.show(5, truncate=False)\n",
        "df_sk = df_sk.drop('Fvec')\n",
        "df_sk = df_sk.select('HeartDisease', 'DenseFvec')\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = df_sk.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Extract the label column\n",
        "label_col = 'HeartDisease'\n",
        "\n",
        "# Extract the training and testing labels\n",
        "train_labels = train_data.select(label_col)\n",
        "test_labels = test_data.select(label_col)\n",
        "train_labels.show(5)\n",
        "\n",
        "train_data.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ADA4K1Fcfvn",
        "outputId": "3f892cc1-86ff-42b0-bf54-08bde4eebd5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "425414\n"
          ]
        }
      ],
      "source": [
        "print(train_labels.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmDUSfwq6s17"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3pYYtSh-wY-0"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwZg_P0p6s17"
      },
      "source": [
        "## -----------------Logistic Regression-----------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5F5OgVU6s17",
        "outputId": "51bc7fa1-dcb9-4691-feaa-d8ea80bcf84b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy = 0.7611645023674465\n",
            "+------------+-----+-----+\n",
            "|HeartDisease|  0.0|  1.0|\n",
            "+------------+-----+-----+\n",
            "|           0|46449|12186|\n",
            "|           1|13287|34733|\n",
            "+------------+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lr = LogisticRegression(maxIter=10, regParam=0.01,featuresCol='DenseFvec', labelCol='HeartDisease')\n",
        "model = lr.fit(train_data)\n",
        "predictions = model.evaluate(test_data)\n",
        "\n",
        "evaluator1 = MulticlassClassificationEvaluator(labelCol='HeartDisease', predictionCol='prediction', metricName='accuracy')\n",
        "accuracy = evaluator1.evaluate(predictions.predictions)\n",
        "print(f'Test Accuracy = {accuracy}')\n",
        "# generate the confusion matrix\n",
        "confusion_matrix_lr = predictions.predictions.groupBy('HeartDisease').pivot('prediction').count().na.fill(0)\n",
        "confusion_matrix_lr.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfm1UkNQC9ia",
        "outputId": "925e8522-67a1-434b-9a12-3ba863ecc4a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score for each class: 0.76089036036038\n",
            "Macro avg F1 score: 0.76089036036038\n",
            "Micro avg F1 score: 0.76089036036038\n"
          ]
        }
      ],
      "source": [
        "evaluator2 = MulticlassClassificationEvaluator(labelCol='HeartDisease', predictionCol='prediction', metricName='f1')\n",
        "\n",
        "# calculate the f1 score for each class\n",
        "f1 = evaluator2.evaluate(predictions.predictions, {evaluator.metricName: \"f1ByLabel\"})\n",
        "\n",
        "# calculate the macro avg f1 score\n",
        "macro_avg_f1 = evaluator2.evaluate(predictions.predictions, {evaluator.metricName: \"weightedFMeasure\", evaluator.weightCol: \"label\"})\n",
        "\n",
        "# calculate the micro avg f1 score\n",
        "micro_avg_f1 = evaluator2.evaluate(predictions.predictions, {evaluator.metricName: \"f1\"})\n",
        "\n",
        "print(\"F1 score for each class:\", f1)\n",
        "print(\"Macro avg F1 score:\", macro_avg_f1)\n",
        "print(\"Micro avg F1 score:\", micro_avg_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOyVCPX9IeF3",
        "outputId": "462f2989-50eb-45b2-88df-a08c6efeb7a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix after oversampling: \n",
            " [[46449 12186]\n",
            " [13287 34733]]\n",
            "Classification report after oversampling: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.79      0.78     58635\n",
            "           1       0.74      0.72      0.73     48020\n",
            "\n",
            "    accuracy                           0.76    106655\n",
            "   macro avg       0.76      0.76      0.76    106655\n",
            "weighted avg       0.76      0.76      0.76    106655\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_test = test_labels.toPandas().values\n",
        "y_test_ = y_test.flatten().tolist()\n",
        "y_pred = predictions.predictions.select('prediction').toPandas().values\n",
        "y_pred_ = y_pred.flatten().tolist()\n",
        "print('Confusion matrix after oversampling: \\n', confusion_matrix(y_test_, y_pred_))\n",
        "# show the classification report\n",
        "print('Classification report after oversampling: \\n', classification_report(y_test_, y_pred_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0LA_slE6s18"
      },
      "source": [
        "## -----------------Naive Bayes-----------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU_6lth66s19",
        "outputId": "09997b96-1f5f-4c96-baca-3eb5027fa478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.6541465472786085\n",
            "F1 score:  0.6325471656455405\n"
          ]
        }
      ],
      "source": [
        "# Use the MLlib API to create and train a Naive Bayes model on the training data\n",
        "nb = NaiveBayes(featuresCol='DenseFvec', labelCol='HeartDisease')\n",
        "nbModel = nb.fit(train_data)\n",
        "\n",
        "# Use the model to make predictions on the test data\n",
        "predictions_nb = nbModel.transform(test_data)\n",
        "\n",
        "# Evaluate the model's performance using various metrics\n",
        "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"HeartDisease\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"HeartDisease\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "\n",
        "accuracy = evaluator_acc.evaluate(predictions_nb)\n",
        "f1_score = evaluator_f1.evaluate(predictions_nb)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"F1 score: \", f1_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74OrQV1trYCS",
        "outputId": "a74ced67-ad2b-4f86-c03a-6d5e986042ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "Confusion matrix after oversampling: \n",
            " [[50550  8085]\n",
            " [28802 19218]]\n",
            "Classification report after oversampling: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.86      0.73     58635\n",
            "           1       0.70      0.40      0.51     48020\n",
            "\n",
            "    accuracy                           0.65    106655\n",
            "   macro avg       0.67      0.63      0.62    106655\n",
            "weighted avg       0.67      0.65      0.63    106655\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = predictions_nb.select('prediction').toPandas().values\n",
        "y_pred_ = y_pred.flatten().tolist()\n",
        "print('Confusion matrix after oversampling: \\n', confusion_matrix(y_test_, y_pred_))\n",
        "# show the classification report\n",
        "print('Classification report after oversampling: \\n', classification_report(y_test_, y_pred_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpA8grQc6s19"
      },
      "source": [
        "## -----------------SVM-----------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C_zCfhx6s19",
        "outputId": "8f6beb39-f413-4a90-9f0d-1ec9969d0420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.762608410294876\n",
            "F1 score:  0.762786271251688\n"
          ]
        }
      ],
      "source": [
        "# Use the MLlib API to create and train a Linear SVM model on the training data\n",
        "svm = LinearSVC(featuresCol='DenseFvec', labelCol='HeartDisease', maxIter=10)\n",
        "svmModel = svm.fit(train_data)\n",
        "# Use the model to make predictions on the test data\n",
        "predictions_svm = svmModel.transform(test_data)\n",
        "\n",
        "# Evaluate the model's performance using various metrics\n",
        "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"HeartDisease\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"HeartDisease\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "\n",
        "accuracy = evaluator_acc.evaluate(predictions_svm)\n",
        "f1_score = evaluator_f1.evaluate(predictions_svm)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"F1 score: \", f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfBOruJMsDiV",
        "outputId": "08ad2046-69b1-495c-e065-af90e0a9469e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "Confusion matrix after oversampling: \n",
            " [[45542 13093]\n",
            " [12226 35794]]\n",
            "Classification report after oversampling: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.78      0.78     58635\n",
            "           1       0.73      0.75      0.74     48020\n",
            "\n",
            "    accuracy                           0.76    106655\n",
            "   macro avg       0.76      0.76      0.76    106655\n",
            "weighted avg       0.76      0.76      0.76    106655\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = predictions_svm.select('prediction').toPandas().values\n",
        "y_pred_ = y_pred.flatten().tolist()\n",
        "print('Confusion matrix after oversampling: \\n', confusion_matrix(y_test_, y_pred_))\n",
        "# show the classification report\n",
        "print('Classification report after oversampling: \\n', classification_report(y_test_, y_pred_))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}